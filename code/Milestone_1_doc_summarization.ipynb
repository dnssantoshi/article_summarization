{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a single summary for all the articles in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/san/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Necessary imports\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import networkx as nx\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the dataset into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/sports_articles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('article_id',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maria Sharapova has basically no friends as te...</td>\n",
       "      <td>https://www.tennisworldusa.org/tennis/news/Mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BASEL, Switzerland (AP), Roger Federer advance...</td>\n",
       "      <td>http://www.tennis.com/pro-game/2018/10/copil-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roger Federer has revealed that organisers of ...</td>\n",
       "      <td>https://scroll.in/field/899938/tennis-roger-fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kei Nishikori will try to end his long losing ...</td>\n",
       "      <td>http://www.tennis.com/pro-game/2018/10/nishiko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Federer, 37, first broke through on tour over ...</td>\n",
       "      <td>https://www.express.co.uk/sport/tennis/1036101...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 article_text  \\\n",
       "article_id                                                      \n",
       "1           Maria Sharapova has basically no friends as te...   \n",
       "2           BASEL, Switzerland (AP), Roger Federer advance...   \n",
       "3           Roger Federer has revealed that organisers of ...   \n",
       "4           Kei Nishikori will try to end his long losing ...   \n",
       "5           Federer, 37, first broke through on tour over ...   \n",
       "\n",
       "                                                       source  \n",
       "article_id                                                     \n",
       "1           https://www.tennisworldusa.org/tennis/news/Mar...  \n",
       "2           http://www.tennis.com/pro-game/2018/10/copil-s...  \n",
       "3           https://scroll.in/field/899938/tennis-roger-fe...  \n",
       "4           http://www.tennis.com/pro-game/2018/10/nishiko...  \n",
       "5           https://www.express.co.uk/sport/tennis/1036101...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three features in the sports articles dataset \n",
    "1. article_id\n",
    "2. article_text\n",
    "3. source\n",
    "\n",
    "The most important feature of these is 'article_text' which contains the text of articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine sample article text using below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Maria Sharapova has basically no friends as tennis players on the WTA Tour. The Russian player has no problems in openly speaking about it and in a recent interview she said: 'I don't really hide any feelings too much. I think everyone knows this is my job here. When I'm on the courts or when I'm on the court playing, I'm a competitor and I want to beat every single person whether they're in the locker room or across the net.So I'm not the one to strike up a conversation about the weather and know that in the next few minutes I have to go and try to win a tennis match. I'm a pretty competitive girl. I say my hellos, but I'm not sending any players flowers as well. Uhm, I'm not really friendly or close to many players. I have not a lot of friends away from the courts.' When she said she is not really close to a lot of players, is that something strategic that she is doing? Is it different on the men's tour than the women's tour? 'No, not at all. I think just because you're in the same sport doesn't mean that you have to be friends with everyone just because you're categorized, you're a tennis player, so you're going to get along with tennis players. I think every person has different interests. I have friends that have completely different jobs and interests, and I've met them in very different parts of my life. I think everyone just thinks because we're tennis players we should be the greatest of friends. But ultimately tennis is just a very small part of what we do. There are so many other things that we're interested in, that we do.'\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['article_text'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Text into Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize n empty array\n",
    "sentences = []\n",
    "\n",
    "# Iterate over each article\n",
    "for s in df['article_text']:\n",
    "  sentences.append(sent_tokenize(s))\n",
    "\n",
    "# Flatten the list\n",
    "sentences = [y for x in sentences for y in x] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Maria Sharapova has basically no friends as tennis players on the WTA Tour.',\n",
       " \"The Russian player has no problems in openly speaking about it and in a recent interview she said: 'I don't really hide any feelings too much.\",\n",
       " 'I think everyone knows this is my job here.',\n",
       " \"When I'm on the courts or when I'm on the court playing, I'm a competitor and I want to beat every single person whether they're in the locker room or across the net.So I'm not the one to strike up a conversation about the weather and know that in the next few minutes I have to go and try to win a tennis match.\",\n",
       " \"I'm a pretty competitive girl.\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the sentences after the split\n",
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuations, numbers and special characters\n",
    "clean_sentences = pd.Series(sentences).str.replace(\"[^a-zA-Z]\", \" \")\n",
    "\n",
    "# Translate alphabets to lowercase\n",
    "clean_sentences = [s.lower() for s in clean_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set stopwords to English\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to remove stopwords\n",
    "def remove_stopwords(sen):\n",
    "    sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
    "    return sen_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords from the sentences\n",
    "clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vector Representation of Sentences\n",
    "vectorizer = TfidfVectorizer(norm = False, smooth_idf = False)\n",
    "sentence_vectors = vectorizer.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 414)\t5.77912349311153\n",
      "  (0, 589)\t5.77912349311153\n",
      "  (0, 312)\t2.9459101490553135\n",
      "  (0, 84)\t5.77912349311153\n",
      "  (0, 466)\t3.58189891577531\n",
      "  (0, 284)\t3.987364023883474\n",
      "  (0, 67)\t3.6996819514316934\n",
      "  (0, 646)\t3.4765384001174837\n",
      "  (0, 512)\t3.1400661634962708\n",
      "  (0, 478)\t2.64362927718238\n",
      "  (0, 650)\t1.409675640644508\n",
      "  (0, 750)\t5.085976312551584\n",
      "  (0, 682)\t4.392829131991639\n",
      "  (1, 312)\t2.9459101490553135\n",
      "  (1, 466)\t3.58189891577531\n",
      "  (1, 650)\t1.409675640644508\n",
      "  (1, 564)\t5.77912349311153\n",
      "  (1, 511)\t5.085976312551584\n",
      "  (1, 526)\t5.77912349311153\n",
      "  (1, 341)\t3.815844964407277\n",
      "  (1, 484)\t5.77912349311153\n",
      "  (1, 616)\t5.085976312551584\n",
      "  (1, 31)\t4.169685580677429\n",
      "  (1, 356)\t2.834684513945089\n",
      "  (1, 53)\t1.9949338591932682\n",
      "  :\t:\n",
      "  (117, 341)\t1.9079224822036385\n",
      "  (117, 47)\t3.6996819514316934\n",
      "  (117, 711)\t3.833213344056216\n",
      "  (117, 655)\t4.169685580677429\n",
      "  (117, 61)\t4.68051120444342\n",
      "  (117, 238)\t5.085976312551584\n",
      "  (117, 133)\t5.085976312551584\n",
      "  (117, 442)\t5.085976312551584\n",
      "  (117, 681)\t5.77912349311153\n",
      "  (117, 576)\t5.77912349311153\n",
      "  (117, 79)\t5.77912349311153\n",
      "  (117, 619)\t5.77912349311153\n",
      "  (117, 493)\t5.77912349311153\n",
      "  (117, 240)\t5.77912349311153\n",
      "  (117, 74)\t5.77912349311153\n",
      "  (118, 650)\t1.409675640644508\n",
      "  (118, 341)\t1.9079224822036385\n",
      "  (118, 356)\t2.834684513945089\n",
      "  (118, 468)\t3.0710732920093196\n",
      "  (118, 88)\t4.392829131991639\n",
      "  (118, 381)\t3.833213344056216\n",
      "  (118, 726)\t4.392829131991639\n",
      "  (118, 719)\t3.4765384001174837\n",
      "  (118, 50)\t4.68051120444342\n",
      "  (118, 213)\t5.77912349311153\n"
     ]
    }
   ],
   "source": [
    "print(sentence_vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
